---
permalink: /
title: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! I am a first-year Ph.D. student advised by Prof. [Kuk-Jin Yoon](https://scholar.google.co.kr/citations?user=1NvBj_gAAAAJ&hl=en) at the [Visual Intelligence Lab (VILab)](https://vi.kaist.ac.kr/), Korea Advanced Institute of Science and Technology (KAIST).
<br/>

My research focuses on developing methods that <b>reliably extract and utilize semantic information from visual data</b>.
I am broadly interested in how models can maintain semantic consistency across domains, modalities, and interaction scenarios.
<br/>

Recently, I have become increasingly interested in <b>multimodal setting and representation learning</b>, including how strong foundation models—such as <b>VLA models, diffusion models, and SAM/SAM2-style segmentation systems</b>—can be adapted and leveraged for robust visual understanding.
I am also exploring <b>egocentric perception</b> and the integration of cues like eye-gaze to enhance semantic interpretation and user interaction in immersive VR/AR environments.
<br/>

Ultimately, my research aims to understand how semantic structures can be extracted from diverse visual modalities and effectively applied to create more adaptive and intelligent perception systems.
I am always open to discussions and collaborations—feel free to reach out anytime!
<br/>

My CV can be found in [here](https://kwonhoyong3.github.io/assets/docs/HoyongKwon_KAIST_Robotics_CV.pdf)
<br/>




Publications
======
<div style="display: flex; align-items: center;">
    <img src='/images/publication_images/ICCV25_DCTTA_fig.png' alt='ICCV 2025' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation<br>
        Jihun Kim*, <b>Hoyong Kwon*</b>, Hyeokjun Kweon*, Wooseong Jeong, Kuk-Jin Yoon<br>
        <b>International Conference on Computer Vision (ICCV) 2025</b><br>
        <div class="pub-links">
            <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Kim_DC-TTA_Divide-and-Conquer_Framework_for_Test-Time_Adaptation_of_Interactive_Segmentation_ICCV_2025_paper.pdf">Paper</a>
            <span>|</span>
            <a href="https://openaccess.thecvf.com/content/ICCV2025/supplemental/Kim_DC-TTA_Divide-and-Conquer_Framework_ICCV_2025_supplemental.zip">Supp</a>
            <span>|</span>
            <a href="https://arxiv.org/abs/2506.23104">ArXiv</a>
            <span>|</span>
            <a href="https://github.com/jihun1998/DCTTA">Code</a>
        </div>
    </div>
</div>
<br/>
<div style="display: flex; align-items: center;">
    <img src='/images/publication_images/ECCV24_WSSS_PCSS_fig.png' alt='ECCV 2024' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        Phase Concentration and Shortcut Suppression for Weakly Supervised Semantic Segmentation<br>
        <b>Hoyong Kwon</b>, Jaeseok Jeong, Sung-Hoon Yoon, Kuk-Jin Yoon<br>
        <b>European Conference on Computer Vision (ECCV) 2024</b><br>
        <div class="pub-links">
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04729.pdf">Paper</a>
            <span>|</span>
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04729-supp.pdf">Supp</a>
            <span>|</span>
            <a href="https://github.com/kwonhoyong3/PCSS-WSSS">Code</a>
        </div>
    </div>
</div>
<br/>
<div style="display: flex; align-items: center;">
    <img src='/images/publication_images/ECCV24_WSSS_DiG_fig.png' alt='ECCV 2024' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        Diffusion-Guided Weakly Supervised Semantic Segmentation<br>
        Sung-Hoon Yoon, <b>Hoyong Kwon*</b>, Jaeseok Jeong*, Daehee Park, Kuk-Jin Yoon<br>
        <b>European Conference on Computer Vision (ECCV) 2024</b><br>
        <div class="pub-links">
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06482.pdf">Paper</a>
            <span>|</span>
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06482-supp.pdf">Supp</a>
            <span>|</span>
            <a href="https://github.com/yoon307/DiG">Code</a>
        </div>
    </div>
</div>
<br/>
<div style="display: flex; align-items: center;">
    <img src='/images/publication_images/CVPR24_WSSS_CTI_fig.png' alt='CVPR 2024' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        Class Tokens Infusion for Weakly Supervised Semantic Segmentation<br>
        Sung-Hoon Yoon, <b>Hoyong Kwon</b>, Hyeonseong Kim, Kuk-Jin Yoon<br>
        <b>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024</b><br>
        <div class="pub-links">
            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yoon_Class_Tokens_Infusion_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf">Paper</a>
            <span>|</span>
            <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Yoon_Class_Tokens_Infusion_CVPR_2024_supplemental.pdf">Supp</a>
            <span>|</span>
            <a href="https://github.com/yoon307/CTI">Code</a>
        </div>
    </div>
</div>
<br/>

<style>
    .publication-container {
        display: flex;
        align-items: center;
    }

    .publication-image {
        margin-right: 13px;
        width: 250px; /* Default width */
        height: 140px; /* Default height */
    }

    .publication-image-simulation {
        margin-right: 13px;
        width: 250px; /* Default width */
        height: 190px; /* Default height */
    }

    .publication-image-narrow {
        margin-right: 13px;
        width: 180px; /* Default width */
        height: 240px; /* Default height */
    }

    .publication-image-middle {
        margin-right: 13px;
        width: 205px; /* Default width */
        height: 185px; /* Default height */
    }

    .publication-info {
        flex-grow: 1; /* Allow text to expand */
    }

    /* Media query for smaller screens (e.g., mobile devices) */
    @media (max-width: 1000px) {
        .publication-image {
            width: 150px; /* Adjusted width for smaller screens */
            height: 84px; /* Adjusted height for smaller screens */
        }
    }

    @media (max-width: 1000px) {
        .publication-image-simulation {
            width: 150px; /* Adjusted width for smaller screens */
            height: 120px; /* Adjusted height for smaller screens */
        }
    }
    
    @media (max-width: 1000px) {
        .publication-image-narrow {
            width: 100px; /* Adjusted width for smaller screens */
            height: 133px; /* Adjusted height for smaller screens */
        }
    }

    @media (max-width: 1000px) {
        .publication-image-middle {
            width: 110px; /* Adjusted width for smaller screens */
            height: 100px; /* Adjusted height for smaller screens */
        }
    }
    
</style>


Selected Honors and Awards
======
- 2023 / Magna Cum Laude, KAIST BS
- 2021-2022 / National Science & Technology Scholarship, Korea Student Aid Foundation
- 2020 / Dean's List, KAIST College of Engineering
<br/>



Research Experiences
======
- 2025.03 - Present / <b>Project Leader</b> / Development of Mobility and Connectivity Platform for Unmanned Autonomous Delivery / Multi-Modal Fusion, 3D Object&Lane Detection, ROS2
<br/>
- 2024.01 - 2025.02 / <b>Project Member</b> / Development of Mobility and Connectivity Platform for Unmanned Autonomous Delivery / Multi-Modal Fusion, 3D Object&Lane Detection, ROS2
<br/>
- 2022.03 - 2022.08 / <b>Internship</b> / NCSOFT Vision AI Lab Recognition Team / Keypoint Detection, Markerless Face Wrapping
